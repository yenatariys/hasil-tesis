# ðŸ“Š PRESENTATION OUTLINE: CHAPTER III - METHODOLOGY
## **Compact 5-Slide Structure: Thesis Flow & CRISP-DM Framework**

**Context**: Research Methodology following CRISP-DM  
**Target**: 5 compact slides covering overall flow + framework  
**Time Allocation**: ~6-7 minutes  
**Approach**: Systematic explanation from problem to deployment

---

## **SLIDE 1: Thesis Research Flow Overview (60 seconds)**

**Title**: Research Flow: From Problem to Deployment

**Visual**: Three-panel flowchart showing MULAI â†’ FENOMENA â†’ PERMASALAHAN â†’ SOLUSI PENELITIAN â†’ DATA â†’ PREPROCESSING â†’ MODELING â†’ HASIL â†’ MANFAAT â†’ SELESAI

**Content**:

```
ðŸŽ¯ SYSTEMATIC RESEARCH PROGRESSION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ðŸ“ PHASE 1: FENOMENA (Problem Context)
   ðŸŽ¬ OTT streaming growth in Indonesia & Southeast Asia
   â­ Rating disparity: App Store 4.8/5 vs Play Store 2.0/5
   ðŸ’° 2023 Disney+ Hotstar price increase â†’ subscriber decline

ðŸ“ PHASE 2: PERMASALAHAN (Research Problem)
   â“ Incomplete ratings (missing aspects/inconsistent)
   ðŸŽ¯ 2023 price increase impact on sentiment unclear

ðŸ“ PHASE 3: SOLUSI PENELITIAN (Solution)
   ðŸ¤– SVM sentiment analysis comparing:
      â€¢ TF-IDF (Traditional bag-of-words)
      â€¢ IndoBERT embeddings (Modern contextual)

ðŸ“ PHASE 4: HASIL (Results)
   ðŸ“Š Raw data â†’ Cleaned data â†’ Trained models
   âœ… Sentiment distribution analysis
   âœ… TF-IDF vs IndoBERT performance comparison

ðŸ“ PHASE 5: MANFAAT (Impact)
   ðŸŽ“ Academic: Indonesian NLP contribution
   ðŸ’¼ Business: Actionable insights for product decisions
   âš™ï¸ Practical: Interactive dashboard deployment
```

**Speaking Points** (60 sec):
> "Our research follows a systematic 5-phase flow. We identified the phenomenonâ€”Disney+ Hotstar's rating disparity and 2023 price increase. This led to our research problemâ€”incomplete ratings failing to capture nuanced sentiment. Our solution? Compare traditional TF-IDF versus modern IndoBERT for Indonesian sentiment classification using SVM. The results provide actionable insights for business decisions, and we deliver this through an interactive dashboard."

---

## **SLIDE 2: CRISP-DM Framework - The Foundation (90 seconds)**

**Title**: CRISP-DM: Industry-Standard Methodology for Data Mining

**Visual**: Circular CRISP-DM diagram with 6 interconnected phases

**Content**:

```
ðŸ“ 6-PHASE ITERATIVE FRAMEWORK:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1ï¸âƒ£ BUSINESS UNDERSTANDING                          â”‚
â”‚    â€¢ Research Objectives: Automated sentiment        â”‚
â”‚      classification for Indonesian reviews          â”‚
â”‚    â€¢ Success Criteria: Model performance &          â”‚
â”‚      business value metrics                         â”‚
â”‚    â€¢ Primary Question: TF-IDF vs IndoBERT?          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2ï¸âƒ£ DATA UNDERSTANDING                              â”‚
â”‚    â€¢ Sources: App Store + Play Store                â”‚
â”‚    â€¢ Total: 838 Ã— 2 platforms = 1,676 reviews       â”‚
â”‚    â€¢ Periods: 2020-2022 (419) + 2023-2025 (419)     â”‚
â”‚    â€¢ Collection: April 2025 scraping                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3ï¸âƒ£ DATA PREPARATION                                â”‚
â”‚    â€¢ 6-Stage Pipeline:                              â”‚
â”‚      1. Translation (Google Translate)              â”‚
â”‚      2. Cleaning (lowercase + noise removal)        â”‚
â”‚      3. Tokenization (NLTK)                         â”‚
â”‚      4. Stopword Removal (758 Indonesian stopwords) â”‚
â”‚      5. Stemming (Sastrawi)                         â”‚
â”‚      6. Final Text (`ulasan_bersih`)                â”‚
â”‚    â€¢ Labeling: InSet lexicon (10,218 terms)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4ï¸âƒ£ MODELING                                        â”‚
â”‚    â€¢ Feature Extraction:                            â”‚
â”‚      - TF-IDF: Max 5,000 features                   â”‚
â”‚        â€¢ N-grams tested: (1,1), (1,2), (1,3)        â”‚
â”‚      - IndoBERT: 768-dimensional embeddings         â”‚
â”‚    â€¢ Classifier: SVM (Linear kernel)                â”‚
â”‚    â€¢ Tuning: GridSearchCV (10-fold CV)              â”‚
â”‚      - TF-IDF: n-gram (1,1)-(1,3), C âˆˆ {0.001,      â”‚
â”‚        0.01, 0.1, 1, 10, 100}, kernel âˆˆ {linear,    â”‚
â”‚        rbf, poly}                                   â”‚
â”‚      - IndoBERT: C âˆˆ {0.001, 0.01, 0.1, 1, 10,      â”‚
â”‚        100}, kernel âˆˆ {linear, rbf, poly}           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5ï¸âƒ£ EVALUATION                                      â”‚
â”‚    â€¢ Primary Metric: Macro F1-Score                 â”‚
â”‚      (handles 82% negative imbalance)               â”‚
â”‚    â€¢ Secondary Metric: Accuracy                     â”‚
â”‚    â€¢ Validation: Stratified 80:20 split             â”‚
â”‚    â€¢ Analysis: Cross-platform comparison            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6ï¸âƒ£ DEPLOYMENT                                      â”‚
â”‚    â€¢ Platform: Streamlit dashboard                  â”‚
â”‚    â€¢ Features: Real-time prediction, visualizations â”‚
â”‚    â€¢ Users: Customer support, product managers      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… WHY CRISP-DM?
â€¢ Industry-standard framework (proven methodology)
â€¢ Iterative approach (can revisit phases as needed)
â€¢ Ensures reproducibility and transparency
â€¢ Bridges business objectives to technical implementation
```

**Speaking Points** (90 sec):
> "CRISP-DM ensures systematic progression through six iterative phases. We start by understanding business needsâ€”sentiment analysis for Disney+ Hotstar with macro F1 â‰¥ 0.50 as our success criterion. Data understanding involves collecting 1,676 reviews across two platforms and time periods split by the 2023 price increase. Data preparation transforms raw Indonesian text through a 6-stage preprocessing pipeline (translation, cleaning, tokenization, stopword removal, stemming, final text). Modeling compares TF-IDF versus IndoBERT features with SVM classifiers tuned via grid searchâ€”we test three n-gram settings for TF-IDF and multiple C and kernel parameters for both methods. Evaluation uses macro F1-score as the primary metric to handle severe class imbalanceâ€”82% negative on Play Store. Finally, deployment makes models accessible through an interactive Streamlit dashboard for real-time predictions."

---

## **SLIDE 3: Data Pipeline Flow - From Raw to Predictions (90 seconds)**

**Title**: End-to-End Data Pipeline

**Visual**: Flowchart showing DATA â†’ PREPROCESSING â†’ LABELING â†’ FEATURE EXTRACTION â†’ CLASSIFICATION â†’ RESULTS

**Content**:

```
ðŸ“Š COMPLETE DATA TRANSFORMATION PIPELINE:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ðŸ”¹ INPUT: RAW DATA
   â€¢ App Store: 838 reviews (2020-2025)
   â€¢ Play Store: 838 reviews (2020-2025)
   â€¢ Temporal Split:
     - Period 1 (2020-2022): Pre-price increase - 419 each
     - Period 2 (2023-2025): Post-price increase - 419 each
   â€¢ Attributes: userName, score (1-5â˜…), content, timestamp

ðŸ”¹ STAGE 1: PREPROCESSING (6 Steps)
   Step 1: Translation â†’ Indonesian (googletrans)
   Step 2: Cleaning â†’ lowercase, strip url/punctuation/numbers, collapse spaces
   Step 3: Tokenization â†’ Word tokens (NLTK)
   Step 4: Stopword Removal â†’ Filter 758 Indonesian stopwords
      âš ï¸ Creates empty strings (App: 8, Play: 43)
   Step 5: Stemming â†’ Root form (Sastrawi)
      Example: "menyenangkan" â†’ "senang"
   Step 6: Final Text â†’ stored as `ulasan_bersih`

ðŸ”¹ STAGE 2: SENTIMENT LABELING (Lexicon-Based)
   â€¢ Method: InSet dictionary (10,218 terms)
     - 3,609 positive words
     - 6,609 negative words
   â€¢ Algorithm:
     IF pos_count > neg_count â†’ "Positif"
     IF neg_count > pos_count â†’ "Negatif"
     IF pos_count == neg_count â†’ "Netral"
   
   â€¢ Output Distribution:
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Platform     â”‚ Positif â”‚ Netral  â”‚ Negatif  â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚ App Store    â”‚ 16%     â”‚ 18%     â”‚ 66% âš ï¸   â”‚
     â”‚ Play Store   â”‚ 7%      â”‚ 11%     â”‚ 82% ðŸ”´   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†’ Severe class imbalance justifies Macro F1 metric

ðŸ”¹ STAGE 3: FEATURE EXTRACTION (2 Methods)
   
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Method 1: TF-IDF (Traditional)                  â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ â€¢ Max features: 5,000                           â”‚
   â”‚ â€¢ N-gram tested: (1,1), (1,2), (1,3)            â”‚
   â”‚ â€¢ Output: Sparse matrix                         â”‚
   â”‚   - App Store: (830, 1688)                      â”‚
   â”‚   - Play Store: (795, 1368)                     â”‚
   â”‚ â€¢ Advantages:                                   â”‚
   â”‚   âœ… Efficient (~30 sec training)               â”‚
   â”‚   âœ… Interpretable (actual words)               â”‚
   â”‚ â€¢ Limitations:                                  â”‚
   â”‚   âŒ No word order/context                      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Method 2: IndoBERT (Modern)                     â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ â€¢ Model: IndoBERT-base-p1                       â”‚
   â”‚ â€¢ Embedding dim: 768                            â”‚
   â”‚ â€¢ Output: Dense matrix (n_samples, 768)         â”‚
   â”‚ â€¢ Advantages:                                   â”‚
   â”‚   âœ… Contextual understanding                   â”‚
   â”‚   âœ… Semantic similarity                        â”‚
   â”‚ â€¢ Limitations:                                  â”‚
   â”‚   âŒ Expensive (~10-15 min training)            â”‚
   â”‚   âŒ Less interpretable                         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ”¹ STAGE 4: CLASSIFICATION (SVM)
   â€¢ Model: Support Vector Machine
   â€¢ Hyperparameter Tuning: GridSearchCV (10-fold CV)
   â€¢ Search Space:
     - TF-IDF: n-gram {(1,1),(1,2),(1,3)} Ã— C âˆˆ {0.001, 0.01, 0.1, 1, 10, 100}, kernel âˆˆ {linear, rbf, poly}
     - IndoBERT: C âˆˆ {0.001, 0.01, 0.1, 1, 10, 100}, kernel âˆˆ {linear, rbf, poly}
   â€¢ Best Parameters Found (reported in Chapter IV):
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Model            â”‚ C    â”‚ Kernel   â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚ TF-IDF App       â”‚ 100  â”‚ Linear âœ…â”‚
     â”‚ TF-IDF Play      â”‚ 100  â”‚ Linear âœ…â”‚
     â”‚ IndoBERT App     â”‚ 0.01 â”‚ Linear âœ…â”‚
     â”‚ IndoBERT Play    â”‚ 0.01 â”‚ Linear âœ…â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†’ Linear kernels = sentiment is linearly separable
   
   â€¢ Training: 80% stratified split
   â€¢ Testing: 20% hold-out (App: 166, Play: ~159)
   â€¢ Class Weighting: Balanced (inversely proportional)

ðŸ”¹ STAGE 5: RESULTS & EVALUATION
   â€¢ Primary Metric: Macro F1-Score
   â€¢ Secondary Metric: Accuracy
   â€¢ Analysis: Confusion matrices, per-class F1
   â€¢ Comparison: TF-IDF vs IndoBERT, App vs Play
```

**Speaking Points** (90 sec):
> "Raw reviews enter a 6-stage preprocessing pipeline. Translation ensures all text is Indonesian, cleaning normalizes case and strips noise, tokenization splits into words, stopword removal filters 758 function wordsâ€”critical note: this creates empty strings that MUST be filtered before modeling. Sastrawi stemming reduces morphological variants to root forms, producing the `ulasan_bersih` column. InSet lexicon provides ground truth labels showing severe imbalanceâ€”82% negative on Play Store. We then extract features using two methods: TF-IDF creates sparse word-frequency vectors, testing three n-gram configurations, while IndoBERT produces dense 768-dimensional contextual embeddings. Both feed into SVM classifiers optimized via grid search across multiple hyperparameter combinations. After stratified 80:20 split with class balancing, we evaluate on held-out test sets using macro F1 as primary metric."

---

## **SLIDE 4: Why This Methodology? Critical Design Choices (75 seconds)**

**Title**: Methodological Justifications: Key Design Decisions

**Content**:

```
ðŸŽ¯ 5 CRITICAL DESIGN DECISIONS & RATIONALES:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1ï¸âƒ£ WHY COMPARE TF-IDF VS INDOBERT?
   â“ Research Question: Can traditional methods match modern transformers?
   âœ… Controlled Comparison: Same classifier (SVM), same data
      â†’ Isolates feature engineering impact
   ðŸ’¡ Practical Value: TF-IDF cheaper/faster vs IndoBERT sophisticated
   ðŸ“Š Cost-Benefit: TF-IDF 10Ã— faster (0.07s vs 0.82s inference)

2ï¸âƒ£ WHY SVM AS SOLE CLASSIFIER?
   âœ… Handles both sparse (TF-IDF) and dense (IndoBERT) features
   âœ… Linear kernels emerged optimal â†’ sentiment linearly separable
   âœ… Robust to overfitting with proper regularization (C parameter)
   âœ… Eliminates algorithmic variance â†’ fair feature comparison
   âŒ Alternative (Naive Bayes, Random Forest) = adds confounding variables

3ï¸âƒ£ WHY LEXICON-BASED LABELING (InSet)?
   âœ… No pre-labeled Indonesian sentiment dataset available
   âœ… InSet: 10,218 Indonesian terms (largest available lexicon)
      - 3,609 positive terms
      - 6,609 negative terms
   âœ… Provides consistent, reproducible ground truth
   âš ï¸ Limitation: May miss slang/colloquialisms (acknowledged)

4ï¸âƒ£ WHY MACRO F1 AS PRIMARY METRIC? (Most Critical)
   ðŸ”´ Class Imbalance Reality:
      â€¢ App Store: 66% negative
      â€¢ Play Store: 82% negative
   
   âŒ ACCURACY TRAP:
      Naive baseline (always predict "Negatif"):
      â€¢ Play Store: 82% accuracy WITHOUT learning!
      â€¢ App Store: 66% accuracy WITHOUT learning!
      â†’ Accuracy is dangerously misleading
   
   âœ… MACRO F1 SOLUTION:
      â€¢ Treats all 3 classes equally (unweighted average)
      â€¢ Forces minority class detection (Netral, Positif)
      â€¢ Aligns with business needs:
        - Negatif: Identify technical issues âœ…
        - Netral: Early churn signals (retention) ðŸ’¼
        - Positif: Marketing insights (amplify features) ðŸ“ˆ
   
   ðŸ“Š Example Impact:
      Play Store TF-IDF:
      â€¢ Accuracy: 73.21% (looks good!)
      â€¢ Macro F1: 0.38 (reveals poor balance)
      â€¢ Positif F1: 0.11 (near-failure, only 8% recall)
      â†’ Accuracy hides minority class blindness

5ï¸âƒ£ WHY STRATIFIED SPLIT + CLASS BALANCING?
   âœ… Stratified Split: Test set mirrors real-world distribution
   âœ… SVM Class Weighting: Balanced (inversely proportional to freq)
   âœ… Combined Effect: Minority classes not ignored during training
   ðŸ“Š Result:
      â€¢ Training set maintains 66%/82% negative distribution
      â€¢ Model forced to learn ALL three classes
      â€¢ Macro F1 ensures evaluation fairness

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ’¡ SUMMARY: Every choice addresses class imbalance systematically
   â†’ Prevents accuracy-driven optimization that ignores business value
```

**Speaking Points** (75 sec):
> "Every methodological choice has a rationale. We compare TF-IDF versus IndoBERT to answer whether expensive transformers justify their costâ€”TF-IDF is 10Ã— faster. SVM as the sole classifier eliminates algorithmic noiseâ€”performance differences come purely from feature engineering. Lexicon-based labeling with InSet provides ground truth in the absence of pre-labeled datasets. 

> The most critical decision: Macro F1 as primary metric. With 82% negative reviews on Play Store, a naive baseline achieves 82% accuracy without learning anythingâ€”it simply predicts 'Negatif' every time. Accuracy would misleadingly favor models that ignore minority classes. Macro F1 forces balanced detectionâ€”critical because Netral reviews indicate churn risk, and Positif reviews reveal features worth amplifying in marketing. 

> Our three-pronged approachâ€”stratified splitting, class weighting, and macro F1â€”ensures fair evaluation despite extreme imbalance. This prevents accuracy-driven optimization that would deploy a model blind to business-critical minority classes."

---

## **SLIDE 5: From Modeling to Deployment - Delivering Value (60 seconds)**

**Title**: MANFAAT: Three-Layer Impact from Methodology to Practice

**Visual**: Three concentric circles or pyramid showing Academic â†’ Business â†’ Practical deployment

**Content**:

```
ðŸŽ¯ METHODOLOGY DELIVERS VALUE AT 3 LEVELS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ðŸŽ“ LAYER 1: ACADEMIC CONTRIBUTION
   ðŸ“š Literature Contribution:
      â€¢ Indonesian NLP methodology advancement
      â€¢ Controlled TF-IDF vs IndoBERT comparison
      â€¢ Handling severe class imbalance (82% negative)
   ðŸ”¬ Methodological Innovation:
      â€¢ InSet lexicon application for ground truth
      â€¢ Stratified evaluation framework for imbalanced data
      â€¢ Cross-platform comparative analysis

ðŸ’¼ LAYER 2: BUSINESS INSIGHTS
   ðŸ” Temporal Analysis:
      â€¢ Pre-price increase (2020-2022): Baseline sentiment
      â€¢ Post-price increase (2023-2025): Impact assessment
      â€¢ Natural experiment design
   
   ðŸ“Š Actionable Intelligence:
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Sentiment    â”‚ Business Action                   â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      â”‚ Negatif      â”‚ Prioritize technical fixes        â”‚
      â”‚ (66-82%)     â”‚ (login, payment, OTP issues)      â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      â”‚ Netral       â”‚ Identify churn risk users         â”‚
      â”‚ (11-18%)     â”‚ Proactive retention campaigns     â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      â”‚ Positif      â”‚ Amplify successful features       â”‚
      â”‚ (7-16%)      â”‚ Marketing material extraction     â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
   ðŸ’¡ Why Macro F1 Matters for Business:
      â€¢ Accuracy-optimized model: Detects 100% Negatif, 0% Netral/Positif
        â†’ Misses churn signals & marketing opportunities
      â€¢ Macro F1-optimized model: Balanced detection across all classes
        â†’ Comprehensive business intelligence

âš™ï¸ LAYER 3: PRACTICAL DEPLOYMENT
   ðŸ–¥ï¸ Streamlit Dashboard Features:
      
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ 1. Model Selection Panel                        â”‚
      â”‚    â€¢ Platform: App Store / Play Store           â”‚
      â”‚    â€¢ Method: TF-IDF / IndoBERT                  â”‚
      â”‚    â†’ Dynamically loads appropriate .pkl model   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ 2. Real-Time Prediction Engine                  â”‚
      â”‚    â€¢ Input: Paste Indonesian review text        â”‚
      â”‚    â€¢ Output: Sentiment + Confidence scores      â”‚
      â”‚    â€¢ Speed: 0.07s (TF-IDF) vs 0.82s (IndoBERT)  â”‚
      â”‚    â†’ No coding required                         â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ 3. Historical Analytics                         â”‚
      â”‚    â€¢ Sentiment distribution (pie/bar charts)    â”‚
      â”‚    â€¢ Time series trends (2020-2025)             â”‚
      â”‚    â€¢ Rating-sentiment correlation               â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ 4. Model Performance Metrics                    â”‚
      â”‚    â€¢ Confusion matrices (actual vs predicted)   â”‚
      â”‚    â€¢ Classification reports (precision/recall)  â”‚
      â”‚    â€¢ Per-class F1 breakdown                     â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ 5. Linguistic Insights                          â”‚
      â”‚    â€¢ Word clouds per sentiment category         â”‚
      â”‚    â€¢ Dominant keywords extraction               â”‚
      â”‚    â€¢ Cross-platform comparison visualizations   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
   ðŸ‘¥ Target Users:
      â€¢ Customer Support: Prioritize negative review responses
      â€¢ Product Managers: Extract feature requests from Netral/Positif
      â€¢ Marketing Teams: Track sentiment trends, identify amplification opportunities
      â€¢ Executives: Monitor overall sentiment health, price impact

   ðŸš€ Deployment Flow:
      User Input (Review) 
         â†’ Preprocessing Pipeline (5 stages)
         â†’ Feature Extraction (TF-IDF or IndoBERT)
         â†’ SVM Prediction (Load cached .pkl model)
         â†’ Output Display (Sentiment + Confidence)
         â†’ Visualization Update (Real-time charts)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ’¡ METHODOLOGY â†’ DEPLOYMENT BRIDGE:
   Academic rigor ensures reproducibility
   Business focus drives actionable metrics (Macro F1)
   User-friendly interface democratizes access to insights
```

**Speaking Points** (60 sec):
> "Our methodology delivers value at three levels. Academically, we contribute to Indonesian NLP literature by comparing traditional versus modern approaches with rigorous handling of severe class imbalance. For business stakeholders, we provide actionable intelligenceâ€”temporal analysis around the 2023 price increase identifies sentiment patterns. The macro F1 metric ensures we capture ALL business-critical insights: negative reviews for technical fixes, neutral reviews as churn signals, and positive reviews for marketing amplification. 

> For practical adoption, we deploy an interactive Streamlit dashboard requiring zero coding knowledge. Paste a review, select platform and model, receive instant sentiment classification with confidence scores in 0.07 seconds. The dashboard includes five modules: real-time prediction, historical analytics, performance metrics, word clouds, and cross-platform comparisons. Target users span customer support, product managers, marketing teams, and executives. 

> This bridges the gap between academic research and practical business intelligenceâ€”rigorous methodology ensures trustworthy results, while user-friendly deployment democratizes access to insights."

---

## ðŸ“‹ **PRESENTATION STRUCTURE SUMMARY**

| Slide # | Title | Time | Key Focus |
|---------|-------|------|-----------|
| **1** | Thesis Research Flow Overview | 60s | FENOMENA â†’ PERMASALAHAN â†’ SOLUSI â†’ HASIL â†’ MANFAAT |
| **2** | CRISP-DM Framework | 90s | 6 phases with detailed examples |
| **3** | Data Pipeline Flow | 90s | DATA â†’ PREPROCESSING â†’ LABELING â†’ FEATURE EXTRACTION â†’ CLASSIFICATION |
| **4** | Methodological Justifications | 75s | 5 critical design decisions (Why TF-IDF vs IndoBERT? Why Macro F1?) |
| **5** | Deployment & Impact | 60s | Academic â†’ Business â†’ Practical (Dashboard) |
| **TOTAL** | | **6:15 min** | Complete methodology coverage |

---

## ðŸŽ¤ **PRESENTATION SCRIPT - FULL FLOW**

### **Opening (15 seconds)**
> "Good morning/afternoon. Chapter 3 presents our research methodology following CRISP-DM, the industry-standard framework for data mining. Let me walk you through our systematic approach from problem identification to deployed solution."

### **Slide 1 â†’ 2 Transition (5 seconds)**
> "Our research begins with identifying the phenomenonâ€”Disney+ Hotstar's rating disparity and 2023 price increase. To structure this investigation systematically, we adopted the CRISP-DM framework..."

### **Slide 2 â†’ 3 Transition (5 seconds)**
> "Within CRISP-DM's structure, let me detail the complete data pipelineâ€”how raw Indonesian reviews transform into actionable predictions..."

### **Slide 3 â†’ 4 Transition (5 seconds)**
> "Every design choice in this pipeline has a rationale. Why these specific methods? Let me justify five critical decisions..."

### **Slide 4 â†’ 5 Transition (5 seconds)**
> "These methodological choices aren't just academicâ€”they deliver practical value at three levels..."

### **Closing (15 seconds)**
> "To summarize: CRISP-DM ensures systematic progression from business problem to deployed solution. We compare TF-IDF versus IndoBERT using SVM to isolate feature engineering impact. Macro F1 as primary metric handles severe class imbalanceâ€”critical for capturing business-critical minority classes like churn signals and marketing insights. The result? A rigorous methodology validated through an interactive dashboard that democratizes access to sentiment intelligence. Thank you."

---

## ðŸ”‘ **MEMORIZABLE DEFENSE ANSWERS**

**If committee asks about methodology, emphasize these 3 points:**

### **Q1: "Why CRISP-DM?"**
**Answer** (30 seconds):
> "CRISP-DM is the industry standard for data science projects, providing a systematic yet iterative framework from business understanding to deployment. Unlike linear methodologies, CRISP-DM allows revisiting earlier phases as insights emerge. It ensures reproducibility through documented procedures and bridges academic research to practical implementation. In our case, it structured the progression from Disney+ Hotstar's business problemâ€”understanding sentiment around price increasesâ€”through data collection, preprocessing, modeling, evaluation, and finally deployment as an accessible dashboard."

---

### **Q2: "What makes your comparison controlled?"**
**Answer** (30 seconds):
> "Single classifierâ€”SVM. Same dataâ€”1,676 Indonesian reviews. Same preprocessingâ€”6-stage pipeline (translation, cleaning, tokenization, stopword removal, stemming, final text). Only the feature extraction differs: TF-IDF represents the bag-of-words tradition with 5,000 sparse features, IndoBERT represents contextual transformers with 768 dense embeddings. This isolates feature engineering impact, answering whether expensive modern methods justify their cost. Our finding: TF-IDF wins with +0.075 average macro F1 advantage, 10Ã— faster inference, and superior interpretability for business stakeholders."

---

### **Q3: "How do you handle extreme class imbalance?"**
**Answer** (45 seconds):
> "Three-pronged approach addressing imbalance at every stage. First, stratified train-test split preserves the real-world distributionâ€”82% negative on Play Storeâ€”ensuring test set mirrors production. Second, SVM class weighting set to 'balanced' inversely scales by frequency, forcing the model to learn minority classes during training. Third, and most critical: macro F1-score as primary evaluation metric.

> With 82% negative reviews, accuracy is dangerously misleading. A naive baseline that always predicts 'Negatif' achieves 82% accuracy without learning anything. Macro F1 treats all three classes equallyâ€”unweighted averageâ€”forcing balanced detection. This aligns with business needs: Negatif reviews identify technical issues, Netral reviews signal churn risk, Positif reviews reveal marketing opportunities. Accuracy-driven optimization would deploy a model blind to business-critical minority classes. Our approach prevents this trap."

---

## ðŸ“Š **VISUAL SUGGESTIONS FOR EACH SLIDE**

### **Slide 1 Visual:**
- Use the provided 3-panel flowchart image
- Highlight each phase with different colors:
  - FENOMENA: Red (problem context)
  - PERMASALAHAN: Orange (research gap)
  - SOLUSI: Blue (methodology)
  - HASIL: Green (results)
  - MANFAAT: Purple (impact)

### **Slide 2 Visual:**
- Standard CRISP-DM circular diagram
- Annotate each phase with your specific example:
  - Business Understanding: "Macro F1 â‰¥ 0.50"
  - Data Understanding: "1,676 reviews, 2020-2025"
   - Data Preparation: "6-stage pipeline"
  - Modeling: "TF-IDF vs IndoBERT + SVM"
  - Evaluation: "Macro F1 primary metric"
  - Deployment: "Streamlit dashboard"

### **Slide 3 Visual:**
- Linear flowchart with 5 stages
- Show example transformation at each stage:
  - Input: "Aplikasi ini sangat bagus dan menyenangkan"
  - After tokenization: ["Aplikasi", "ini", "sangat", "bagus", "dan", "menyenangkan"]
  - After stopword removal: ["aplikasi", "sangat", "bagus", "menyenangkan"]
  - After stemming: ["aplikasi", "sangat", "bagus", "senang"]
  - Final: "aplikasi sangat bagus senang"

### **Slide 4 Visual:**
- Split screen comparison table:
  - Left column: TF-IDF characteristics
  - Right column: IndoBERT characteristics
  - Middle: Accuracy vs Macro F1 example showing the trap

### **Slide 5 Visual:**
- Three concentric circles or layered pyramid:
  - Outer layer: Academic (literature contribution)
  - Middle layer: Business (actionable insights)
  - Inner layer: Practical (dashboard interface)
- Include small dashboard screenshot mockup

---

## âœ… **PRE-PRESENTATION CHECKLIST**

**Content Covered:**
- âœ… 3.1 Thesis Overall Flow (Slide 1: FENOMENA â†’ MANFAAT)
- âœ… 3.2 CRISP-DM Framework (Slide 2: 6 phases detailed)
- âœ… Data Pipeline Details (Slide 3: 6-stage preprocessing + feature extraction)
- âœ… Methodological Justifications (Slide 4: 5 critical decisions)
- âœ… Deployment & Impact (Slide 5: 3-layer value delivery)

**Time Management:**
- Total: 6 minutes 15 seconds
- Buffer for questions: 3-4 minutes
- Total with Q&A: ~10 minutes (within thesis defense allocation)

**Key Messages:**
1. CRISP-DM = systematic, reproducible, industry-standard
2. Controlled comparison = isolates feature engineering impact
3. Macro F1 = handles imbalance, aligns with business needs
4. Deployment = bridges academic rigor to practical access

**Potential Committee Questions:**
1. "Why not fine-tune IndoBERT instead of just using embeddings?"
2. "How do you validate InSet lexicon accuracy?"
3. "What if slang/colloquialisms aren't in InSet?"
4. "Why not use other classifiers like Naive Bayes or Random Forest?"
5. "How generalizable is this methodology to other Indonesian apps?"

**Backup Slides (Optional):**
- Research timeline (April 2025 data collection)
- Hardware specifications (16GB RAM, GPU optional)
- Ethical considerations (data privacy, bias mitigation)
- Library versions (scikit-learn 1.3+, transformers 4.30+)

---

**End of Presentation Chapter III**
